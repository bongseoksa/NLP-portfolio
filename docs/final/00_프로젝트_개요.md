# NLP-Portfolio 프로젝트 개요

> **문서 버전**: v1.0 (Final)
> **작성일**: 2026-01-05
> **문서 목적**: 프로젝트 초안부터 E2E 테스트까지 전체 구현 가이드

---

## 📋 문서 안내

이 문서는 **NLP-Portfolio** 프로젝트를 처음부터 구축하기 위한 완전한 가이드입니다.
아래 문서들을 **순서대로** 진행하면 프로젝트 생성부터 E2E 테스트까지 완료할 수 있습니다.

### 📂 문서 실행 순서

```
00_프로젝트_개요.md         ← 현재 문서 (프로젝트 이해)
  ↓
01_기술_스택.md             (사용 기술 및 도구 이해)
  ↓
02_시스템_아키텍처.md       (전체 구조 및 설계 원칙 이해)
  ↓
03_환경_설정.md             (개발 환경 준비)
  ↓
04_프로젝트_초기화.md       (프로젝트 생성 및 초기 설정)
  ↓
05_데이터베이스_설정.md     (Supabase 설정 및 스키마 적용)
  ↓
06_임베딩_파이프라인_구축.md (GitHub 데이터 수집 및 임베딩)
  ↓
07_API_서버_구축.md         (Vercel Serverless API 서버)
  ↓
08_프론트엔드_구축.md       (React 기반 UI 구현)
  ↓
09_배포_가이드.md           (Vercel 프로덕션 배포)
  ↓
10_테스트_가이드.md         (E2E 테스트 및 검증)
```

---

## 1. 프로젝트 정의

**NLP-Portfolio**는 복수의 GitHub 리포지토리 코드베이스와 사용자 질의응답 데이터를 자연어로 탐색·분석할 수 있는 **서버리스 기반 NLP 질의응답 시스템**입니다.

### 핵심 특징

- **Zero Server Cost**: 상시 실행 인프라 없이 완전 서버리스 구조
- **CI-based RAG**: GitHub Actions CI에서 임베딩 생성, 정적 벡터 파일 활용
- **Multi-Repository Analysis**: 여러 레포지토리 동시 분석 지원
- **Continuous Q&A**: 이전 대화 컨텍스트를 활용한 연속 질의응답

---

## 2. 프로젝트 목표

### 대목표 (Strategic Goals)

#### 2.1 NLP 기반 질의응답 시스템 구현
- 자연어 질문으로 코드베이스 탐색
- 실시간 답변 생성 (3초 이내)
- 한국어 우선 지원, 영어 호환

#### 2.2 프론트엔드 포트폴리오 활용
- React 기반 SPA 구조
- ChatGPT 스타일 UI/UX
- 반응형 디자인

#### 2.3 다중 페이지 제공
- **Q&A 페이지** (/) - 메인 질의응답 인터페이스
- **대시보드 페이지** (/dashboard) - 통계 및 시각화
- **설정 페이지** (/settings) - 서버 상태 확인

### 중간 목표 (Tactical Goals)

#### 2.4 서버리스 벡터 검색 시스템
- 정적 벡터 파일 (`embeddings.json.gz`) 기반
- GitHub Raw URL 직접 로드 (CDN 비용 없음)
- 메모리 캐시 (5분 TTL)

#### 2.5 다중 GitHub 리포지토리 지원
- 대상: `portfolio`, `NLP-portfolio` (2개 기본, 확장 가능)
- `target-repos.json` 설정 파일 기반
- 증분 업데이트 (신규 커밋만 처리)

#### 2.6 4가지 데이터 소스 임베딩
1. **Commit** - 커밋 메시지 + 메타데이터
2. **Diff** - 변경 내역 patch
3. **File** - 소스 코드 전체
4. **Q&A History** - 이전 질의응답

#### 2.7 Supabase 메타데이터 관리
- PostgreSQL + pgvector extension
- Q&A 원문 저장
- Ping 테이블 (Free Tier 유지)

---

## 3. 타겟 사용자

### 3.1 개발자 포트폴리오 방문자
- 코드베이스를 빠르게 탐색하고 이해하고 싶은 사용자
- 기술 스택과 구현 방식을 자연어로 질문하고 답변 받기

### 3.2 기술 면접관 및 채용 담당자
- 지원자의 프로젝트 구조와 코딩 스타일 파악
- 구현 세부사항에 대한 빠른 확인

### 3.3 프로젝트 코드 리뷰어
- 코드 변경 이력 및 의도 파악
- 특정 기능의 구현 위치 신속 검색

---

## 4. 비즈니스 목표

### 4.1 포트폴리오 차별화
- 일반 정적 포트폴리오가 아닌 AI 시스템 설계 역량 증명
- NLP/RAG/서버리스 기술 통합 경험 시연

### 4.2 비용 최적화
- 월 $0 운영비로 실제 서비스 가능한 시스템 구축
- GitHub Actions, Vercel, Supabase Free Tier 활용

### 4.3 기술 스택 다양성
- NLP, RAG, CI/CD, Serverless 기술 통합 경험
- 프론트엔드 + 백엔드 + AI 통합 시스템 구현

---

## 5. 핵심 설계 원칙

### 5.1 Zero Server Cost (비용 최소화)
- 상시 실행 서버 없음
- 벡터 DB 서버 운영 없음
- CDN 비용 없음 (GitHub Raw URL 활용)

### 5.2 CI-First Architecture (CI 중심 설계)
- 임베딩은 CI 단계에서만 수행
- 런타임은 읽기 전용 구조
- 정적 파일 기반 배포

### 5.3 Incremental Update (증분 업데이트)
- 신규 데이터만 처리하여 비용 절감
- `commit-state.json`으로 중복 방지
- Idempotent 처리 (재실행 안전성)

---

## 6. 프로젝트 구성 요소

### 6.1 프론트엔드 (Frontend)
- **기술**: React 19 + TypeScript + Vite
- **스타일링**: PandaCSS (CSS-in-JS)
- **상태 관리**: Jotai (Client State) + TanStack Query (Server State)
- **라우팅**: React Router v6+

### 6.2 백엔드 (Backend - Serverless)
- **런타임**: Node.js (Vercel Serverless Functions)
- **언어**: TypeScript (ESM 모듈)
- **API**: 15개 Vercel Serverless 엔드포인트 (`api/` 디렉토리)
- **특징**: 상시 실행 서버 없음, 요청 시 실행

### 6.3 AI/ML 스택
- **임베딩 모델**: Hugging Face `sentence-transformers/all-MiniLM-L6-v2` (384 dimensions)
- **응답 생성 LLM**:
  - 1순위: Claude Sonnet 4 (유료, 최고 품질)
  - 2순위: Gemini 1.5 Flash (무료, 중간 품질)
  - 3순위: Mistral-7B-Instruct (무료, 기본 품질)

### 6.4 데이터베이스
- **Primary**: Supabase PostgreSQL (Free Tier)
- **Extension**: pgvector (벡터 검색)
- **용도**: Q&A 원문 저장, 임베딩 벡터 임시 저장 (CI 전용), Ping 기록

### 6.5 벡터 저장 방식
- **Storage**: GitHub Repository (Static File)
- **Format**: `embeddings.json.gz` (gzip 압압)
- **Location**: `output/` 디렉토리
- **Access**: GitHub Raw URL (CDN 비용 없음)

### 6.6 CI/CD
- **GitHub Actions**: 임베딩 파이프라인 (무료 2,000분/월)
- **Vercel**: 프론트엔드 + API 배포 (Hobby Plan 무료)
- **패키지 관리**: pnpm

---

## 7. 주요 기능 목록

### 7.1 다중 레포지토리 질의응답 (F1 - P0)
- 여러 GitHub 레포지토리 코드를 하나의 시스템으로 통합
- 질문 입력 후 3초 이내 응답
- 한국어 질문 지원
- 소스 코드 인용 제공

### 7.2 연속 질의응답 (F2 - P0)
- 이전 대화 컨텍스트 활용
- 후속 질문 자연스럽게 처리
- 예: "차트는 뭐로 만들어졌어?" → "그럼 그 라이브러리 어디서 사용돼?"

### 7.3 대시보드 (F3 - P1)
- 총 질문 수, 성공률, 평균 응답 시간
- 일별 질문 추이 (Line Chart)
- 카테고리별 분포 (Pie Chart)

### 7.4 증분 업데이트 (F4 - P0)
- `commit-state.json`으로 마지막 처리 커밋 추적
- 신규 커밋만 임베딩 생성
- 비용 절감 및 실행 시간 단축

### 7.5 LLM Fallback Chain (F5 - P0)
- 3단계 Fallback으로 가용성 극대화
- Claude → Gemini → Mistral → Error Message

---

## 8. 비기능 요구사항 (NFR)

### NFR1. 성능 (Performance)
- 응답 시간: 95 percentile 3초 이내
- Cold Start: 380ms 이내 (파일 로드)
- Warm Start: 151ms 이내 (캐시 히트)

### NFR2. 가용성 (Availability)
- 목표: 99.5% uptime (주간 기준)
- Fallback: 3단계 LLM Fallback
- 모니터링: Supabase Ping (주간 자동 실행)

### NFR3. 보안 (Security)
- API 키 관리: GitHub Secrets (암호화)
- 환경 변수: `.env` 파일 (git ignore)
- 접근 제어: Supabase RLS (Row Level Security)

### NFR4. 비용 (Cost)
- 목표: 월 $0 운영비
- 제약: GitHub Actions 무료 티어 (2,000분/월)
- 최적화: 증분 업데이트, 캐시 활용

---

## 9. 성공 지표

### 9.1 기술 지표
- ✅ 벡터 검색 정확도 > 80%
- ✅ API 응답 시간 < 3초 (P95)
- ✅ 시스템 가용성 > 99%
- ✅ 에러율 < 1%

### 9.2 비용 지표
- ✅ 월 운영 비용 < $10 (목표: $0)
- ✅ Vercel Free Tier 내 운영
- ✅ Supabase Free Tier 유지
- ✅ LLM API 비용 최적화

### 9.3 사용성 지표
- ✅ Q&A 답변 품질 만족도 > 4.0/5.0
- ✅ 페이지 로드 시간 < 2초
- ✅ 모바일 반응형 지원
- ✅ 접근성 기준 준수 (WCAG 2.1 AA)

---

## 10. 다음 단계

이 문서를 읽었다면, 다음 문서로 진행하세요:

👉 **[01_기술_스택.md](./01_기술_스택.md)** - 사용할 기술 및 도구 상세 설명

---

**문서 작성 완료**: 2026-01-05
**다음 문서**: [01_기술_스택.md](./01_기술_스택.md)
