# 📊 프로젝트 개요

**GitHub Analyzer**는 GitHub에 있는 코드 저장소를 분석하여, 자연어로 질문하면 AI가 답변해주는 시스템입니다.

## 💡 프로젝트 주제 선정 이유

### 배경

개발자들이 새로운 프로젝트 코드를 이해하려면 수많은 파일을 일일이 읽어야 합니다. 특히 신입 개발자나 팀 이동 시 프로젝트와 드베이스를 파악하는 데 많은 시간이 소요됩니다.

### 주제 선정

**실무 활용성**과 **프론트엔드 개발자 관점의 강점**을 살릴 수 있는 주제로 방향을 수렴하여, 최종적으로 **GitHub 레포지토리 기반 소스 코드 분석 및 질의응답 시스템**을 선정하게 되었습니다.

### 해결하려는 문제

이 프로젝트는 다음과 같은 질문에 자동으로 답변해줍니다:

- "이 프로젝트에서 어떤 기능들이 추가되었나요?"
- "API 서버는 어떻게 구현되어 있나요?"
- "프론트엔드에서 어떤 라이브러리를 사용하고 있나요?"
- "최근에 어떤 버그가 수정되었나요?"
- "특정 기능은 언제 추가되었나요?"

### 차별화 포인트

단순한 코드 검색 도구나 챗봇이 아닌, **실제 코드와 변경 히스토리를 기반으로 프로젝트를 설명하는 NLP 시스템**입니다. 질의응답과 시스템 상태를 함께 시각화함으로써 실무 활용성과 교육 과제 요구사항을 동시에 충족합니다.

---

# 📅 작업 계획

## 1-3주차: 주제 선정 및 데이터 기반 구축

### 계획 단계

1-3주차의 목표는 프로젝트 방향을 확정하고, 자연어 처리 시스템의 기반이 되는 데이터 수집 및 파이프라인을 설계·구현하는 것입니다.

- 자연어 처리 프로젝트 전체 구조 이해
- 처리 대상 선정
- 데이터 수집 방식 정의
- 데이터 파이프라인 및 저장 구조 설계

### 실제 진행 과정

프로젝트 초반에는 감성 분석, UX 이슈 자동 검출, FAQ 자동 응답 등 다양한 NLP 주제를 검토하였습니다. 그중 **실무 활용성**과 **프론트엔드 개발자 관점의 강점**을 살릴 수 있는 주제로 방향을 수렴하였습니다.

**최종 주제**: GitHub 레포지토리 기반 소스 코드 분석 및 질의응답 시스템

- 분석 대상: 프론트엔드 레포지토리 (React + Vite 기반 개인 portfolio 프로젝트)
- 데이터 수집 방식:
    - GitHub REST API를 이용한 커밋 메타데이터 수집
    - 로컬 git log 및 git diff를 활용한 변경 이력 수집
    - 소스 코드 전체 파일 수집

## 4-6주차: NLP 모델 설계/구현, 모니터링 시스템 및 대시보드 개발

### 계획된 작업

- 수집된 데이터 검증
- NLP 처리 방식 결정 (사전 학습 모델 활용)
- 임베딩 생성 및 검색 구조 설계
- NLP 시스템의 동작을 시각적으로 관찰할 수 있는 프론트엔드 대시보드 구축

### 진행 방향

- 커밋, 소스 코드, diff를 통합한 텍스트 전처리
- 벡터 데이터 저장
- opneAI, claudeAI 기반 검색

---

# 🎯 핵심 기능

## 1. 자동 데이터 수집

시스템이 자동으로 GitHub 저장소에서 다음 정보를 수집합니다:

- **커밋 히스토리**: 누가, 언제, 무엇을 변경했는지
- **코드 변경 내역**: 어떤 코드가 추가/수정/삭제되었는지
- **소스 코드 파일**: 실제 구현된 코드 내용

## 2. AI 기반 질의응답

사용자가 자연어로 질문하면:

1. 질문을 AI가 이해 가능한 형태로 변환
2. 관련된 코드와 커밋 정보를 검색
3. ChatGPT 또는 Claude AI가 답변 생성
4. 답변과 함께 근거 자료(파일명, 커밋 정보) 제공

## 3. 웹 기반 사용자 인터페이스

3개의 주요 페이지로 구성:

- **Q&A 페이지**: ChatGPT 스타일의 대화형 인터페이스
- **대시보드**: 통계 및 시스템 모니터링
- **설정 페이지**: 서버 상태 확인 및 제어

---

# 🏗️ 시스템 구조

## 시스템이 작동하는 방식

```
사용자 질문 입력
    ↓
웹 브라우저 (React 프론트엔드)
    ↓
API 서버 (질문 처리)
    ↓
벡터 데이터베이스 (관련 정보 검색)
    ↓
AI 엔진 (답변 생성)
    ↓
답변 + 근거 자료 표시
```

## 주요 구성 요소

### 1. 프론트엔드 (사용자가 보는 화면)

- **기술**: React + TypeScript
- **역할**: 사용자 인터페이스 제공
- **포트**: 5173

### 2. API 서버 (중앙 처리 서버)

- **기술**: Node.js + Express
- **역할**: 질문 처리, 데이터 검색, AI 호출
- **포트**: 3001

### 3. Control 서버 (관리 서버)

- **기술**: Node.js + Express
- **역할**: 다른 서버들의 시작/종료 관리
- **포트**: 3000

### 4. ChromaDB (벡터 데이터베이스)

- **기술**: Python 기반 벡터 DB
- **역할**: 코드와 커밋 정보를 검색 가능한 형태로 저장
- **포트**: 8000

### 5. Supabase (클라우드 데이터베이스)

- **기술**: PostgreSQL 기반 클라우드 서비스
- **역할**: 질문 이력 및 통계 저장

---

---

# 🛠️ 구현 방법

## 1. GitHub 데이터 수집 파이프라인

### 개요

GitHub API를 사용하여 커밋 히스토리, 파일 목록, 소스 코드를 수집하고 ChromaDB에 저장하는 파이프라인입니다.

### 주요 기능

### 1) 커밋 히스토리 수집 (`src/pipeline/fetchCommits.ts`)

```tsx
// GitHub API로 pagination 처리하며 모든 커밋 수집
export async function fetchCommits(
  owner: string,
  repo: string
): Promise<CommitData[]> {
  const commits: CommitData[] = [];
  let page = 1;
  const perPage = 100;

  while (true) {
    const response = await octokit.repos.listCommits({
      owner,
      repo,
      per_page: perPage,
      page,
    });

    if ([response.data](http://response.data).length === 0) break;

    commits.push(...[response.data.map](http://response.data.map)(commit => ({
      sha: commit.sha,
      message: commit.commit.message,
      author: [commit.commit.author](http://commit.commit.author)?.name,
      date: [commit.commit.author](http://commit.commit.author)?.date,
      url: commit.html_url,
    })));

    page++;
  }

  return commits;
}
```

### 2) 파일 목록 수집 (`src/pipeline/fetchFiles.ts`)

```tsx
// 레포지토리의 모든 파일 목록 수집
export async function fetchRepositoryFiles(
  owner: string,
  repo: string,
  branch: string = 'main'
): Promise<FileData[]> {
  const tree = await octokit.git.getTree({
    owner,
    repo,
    tree_sha: branch,
    recursive: 'true',
  });

  return [tree.data](http://tree.data).tree
    .filter(item => item.type === 'blob')
    .map(item => ({
      path: item.path!,
      sha: item.sha!,
      url: item.url!,
    }));
}
```

### 3) 소스 코드 내용 수집 (`src/pipeline/fetchFileContent.ts`)

```tsx
// 각 파일의 raw 콘텐트 수집
export async function fetchFileContent(
  owner: string,
  repo: string,
  path: string
): Promise<string> {
  const response = await octokit.repos.getContent({
    owner,
    repo,
    path,
  });

  if ('content' in [response.data](http://response.data)) {
    return Buffer.from([response.data](http://response.data).content, 'base64').toString('utf-8');
  }

  throw new Error('File content not found');
}
```

### 4) 데이터 전처리 및 ChromaDB 저장 (`src/pipeline/runPipeline.ts`)

```tsx
// 대용량 파일을 5KB 단위로 chunk 분할
function chunkLargeFile(content: string, maxSize: number = 5000): string[] {
  if (content.length <= maxSize) return [content];
  
  const chunks: string[] = [];
  for (let i = 0; i < content.length; i += maxSize) {
    chunks.push(content.slice(i, i + maxSize));
  }
  return chunks;
}

// ChromaDB에 데이터 저장
await chromaCollection.add({
  ids: fileIds,
  documents: fileContents,
  metadatas: fileMetadata,
});
```

### 데이터 흐름

```
GitHub API
    ↓
[Commits] + [Files] + [Content]
    ↓
Text Preprocessing (chunk 분할)
    ↓
Embedding 생성 (OpenAI text-embedding-3-small)
    ↓
ChromaDB 저장 (Vector DB)
```

---

## 2. Control 서버

### 개요

API 서버와 ChromaDB 서버를 중앙에서 관리하는 프로세스 제어 서버입니다.

### 주요 기능

### 1) 서버 상태 관리 (`src/control/server.ts`)

```tsx
const processes = new Map<string, ChildProcess>();

// 서버 시작
[app.post](http://app.post)('/start/:serverName', async (req, res) => {
  const { serverName } = req.params;
  
  if (processes.has(serverName)) {
    return res.json({ success: false, message: '이미 실행 중' });
  }

  const child = spawn('pnpm', ['run', `start:${serverName}`], {
    shell: true,
    detached: false,
  });

  processes.set(serverName, child);
  res.json({ success: true, message: `${serverName} 시작됨` });
});

// 서버 종료
[app.post](http://app.post)('/stop/:serverName', (req, res) => {
  const { serverName } = req.params;
  const process = processes.get(serverName);
  
  if (process) {
    process.kill();
    processes.delete(serverName);
    res.json({ success: true });
  }
});
```

### 2) 헬스체크 및 상태 확인

```tsx
// 서버 상태 확인
app.get('/status', async (req, res) => {
  const status = {
    api: await checkServerHealth('http://localhost:3001/health'),
    chroma: await checkServerHealth('http://localhost:8000/api/v1/heartbeat'),
  };
  
  res.json(status);
});

function checkServerHealth(url: string): Promise<boolean> {
  return fetch(url)
    .then(res => res.ok)
    .catch(() => false);
}
```

---

## 3. API 서버

### 개요

프론트엔드와 AI 엔진 사이에서 질의응답을 처리하는 중심 서버입니다.

### 주요 기능

### 1) 질의응답 처리 (`src/api/routes/query.ts`)

```tsx
[app.post](http://app.post)('/api/query', async (req, res) => {
  const { question } = req.body;

  // 1. 질문 임베딩 생성
  const embedding = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: question,
  });

  // 2. ChromaDB에서 유사 문서 검색
  const results = await chromaCollection.query({
    queryEmbeddings: [[embedding.data](http://embedding.data)[0].embedding],
    nResults: 5,
  });

  // 3. 컨텍스트 구성
  const context = results.documents[0].join('\n\n');

  // 4. AI에게 답변 요청 (OpenAI 또는 Claude)
  const completion = await [openai.chat](http://openai.chat).completions.create({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: '당신은 GitHub 레포지토리 분석 전문가입니다.',
      },
      {
        role: 'user',
        content: `컨텍스트:\n${context}\n\n질문: ${question}`,
      },
    ],
  });

  // 5. Supabase에 질문 이력 저장
  await supabase.from('queries').insert({
    question,
    answer: completion.choices[0].message.content,
    created_at: new Date(),
  });

  res.json({
    answer: completion.choices[0].message.content,
    sources: results.metadatas[0],
  });
});
```

### 2) AI 응답 Fallback 메커니즘

```tsx
async function getAIResponse(context: string, question: string) {
  try {
    // 1순위: OpenAI GPT-4
    return await getOpenAIResponse(context, question);
  } catch (error) {
    console.log('OpenAI 실패, Claude로 대체');
    
    try {
      // 2순위: Claude Sonnet 4
      return await getClaudeResponse(context, question);
    } catch (claudeError) {
      throw new Error('All AI providers failed');
    }
  }
}
```

### 3) 질문 유형 분류

```tsx
function classifyQuestionType(question: string): QuestionType {
  const patterns = {
    technical: /(기술|구현|코드|함수|클래스|API)/,
    planning: /(기획|목표|목적|왜)/,
    history: /(언제|변경|수정|커밋)/,
    status: /(현황|상태|진행)/,
    cs: /(알고리즘|자료구조|복잡도)/,
  };

  for (const [type, pattern] of Object.entries(patterns)) {
    if (pattern.test(question)) return type as QuestionType;
  }

  return 'general';
}
```

---

## 4. Frontend (프론트엔드)

### 개요

React 기반의 SPA(단일 페이지 애플리케이션)로 ChatGPT 스타일의 UI를 제공합니다.

### 주요 기능

### 1) 질의응답 인터페이스 (`src/pages/QAPage.tsx`)

```tsx
const QAPage = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');

  const handleSubmit = async () => {
    // 사용자 메시지 추가
    setMessages(prev => [...prev, { role: 'user', content: input }]);

    // API 서버에 질문 전송
    const response = await fetch('http://localhost:3001/api/query', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ question: input }),
    });

    const data = await response.json();

    // AI 답변 추가
    setMessages(prev => [
      ...prev,
      { 
        role: 'assistant', 
        content: data.answer,
        sources: data.sources,
      },
    ]);
  };

  return (
    <div className="chat-container">
      <MessageList messages={messages} />
      <InputBox value={input} onChange={setInput} onSubmit={handleSubmit} />
    </div>
  );
};
```

### 2) 서버 상태 모니터링 (`src/components/ServerStatus.tsx`)

```tsx
const ServerStatus = () => {
  const { data: status } = useQuery({
    queryKey: ['serverStatus'],
    queryFn: async () => {
      const res = await fetch('http://localhost:3000/status');
      return res.json();
    },
    refetchInterval: 5000, // 5초마다 상태 확인
  });

  return (
    <div>
      <StatusIndicator name="API Server" status={status?.api} />
      <StatusIndicator name="ChromaDB" status={status?.chroma} />
    </div>
  );
};
```

### 4) 상태 관리 (Jotai)

```tsx
// 전역 상태
import { atom } from 'jotai';

export const messagesAtom = atom<Message[]>([]);
export const serverStatusAtom = atom<ServerStatus | null>(null);
export const isLoadingAtom = atom<boolean>(false);

// 사용 예시
const [messages, setMessages] = useAtom(messagesAtom);
```

### UI 구조

```
App
 ├─ Navigation
 ├─ QAPage
 │   ├─ MessageList
 │   └─ InputBox
 ├─ DashboardPage
 │   ├─ StatsCard
 │   └─ RecentQueries
 └─ SettingsPage
     └─ ServerStatus
```

# 🔄 사용자 경험 흐름

## 질문부터 답변까지

### 1단계: 질문 입력

사용자가 웹 페이지에서 "이 프로젝트에서 사용하는 기술 스택은?"이라고 질문

### 2단계: 질문 처리

- API 서버가 질문을 받음
- 질문을 AI가 이해할 수 있는 숫자 형태(임베딩)로 변환

### 3단계: 관련 정보 검색

- ChromaDB에서 질문과 관련된 코드/커밋 정보 검색
- 가장 관련성 높은 정보 5-10개 추출

### 4단계: AI 답변 생성

- OpenAI GPT-4 또는 Claude AI에게 질문과 검색 결과 전달
- AI가 자연스러운 답변 생성

### 5단계: 결과 표시

- 답변 텍스트
- 질문 유형 (예: "기술 스택 질문")
- 신뢰도 점수
- 참고한 파일 목록
- 관련 커밋 정보

---

# 📈 프로젝트 진행 현황

## ✅ 완료된 작업

### 백엔드 (서버)

- ✅ GitHub 데이터 수집 파이프라인
- ✅ 커밋 히스토리 분석
- ✅ 소스 코드 파일 수집
- ✅ AI 기반 질의응답 시스템
- ✅ API 서버 구현
- ✅ Control 서버 (프로세스 관리)
- ✅ Supabase 연동 (이력 저장)

### 프론트엔드 (화면)

- ✅ Q&A 페이지 (ChatGPT 스타일)
- ✅ 대시보드 페이지 (통계)
- ✅ 설정 페이지 (서버 제어)
- ✅ 서버 상태 표시기

### 인프라

- ✅ ChromaDB 벡터 저장소
- ✅ Supabase 클라우드 DB
- ✅ 로컬 개발 환경 구축

## 🔄 진행 중인 작업

- 🔄 질문 유형 분류
- 🔄 Vercel 배포 설정 (웹 서비스 공개)
- 🔄 성능 최적화
- 🔄 에러 처리 개선

---

# 🎓 사용된 핵심 기술

## AI/ML 관련

- **OpenAI GPT-4**: 답변 생성 (1순위)
- **Claude Sonnet 4**: 답변 생성 (백업)
- **OpenAI Embedding**: 텍스트를 숫자로 변환
- **ChromaDB**: 벡터 검색 엔진

## 백엔드

- **Node.js**: JavaScript 실행 환경
- **Express.js**: 웹 서버 프레임워크
- **TypeScript**: 타입 안정성을 위한 JavaScript 확장

## 프론트엔드

- **React**: 사용자 인터페이스 라이브러리
- **Vite**: 빠른 개발 환경
- **TanStack Query**: 서버 상태 관리
- **Jotai**: 클라이언트 상태 관리
- **PandaCSS**: 스타일링

## 데이터베이스

- **ChromaDB**: 벡터 데이터베이스 (검색용)
- **Supabase**: PostgreSQL 기반 클라우드 DB (이력 저장용)

## DevOps

- **pnpm**: 패키지 매니저
- **GitHub API**: 코드 저장소 데이터 수집
- **Python**: ChromaDB 실행 환경

---

# 🚀 향후 계획

1. **다중 레포지토리 지원**
    - 여러 GitHub 저장소 동시 분석
    - 레포지토리 간 비교 기능
    - GitHub Webhook 연동을 통한 자동 재인덱싱
2. **다중 출처 자료 지원**
    - PRD, IA, 기획서 등 문서 자료 분석
3. **협업 기능**
    - MCP 연동을 통한 슬랙, 노션 등을 연동한 질문/답변 공유

---

# 💼 비즈니스 가치

## 개발 팀을 위한 가치

1. **온보딩 시간 단축**
    - 신입 개발자가 프로젝트를 빠르게 이해
    - 질문하면 즉시 답변
2. **코드 리뷰 효율화**
    - 변경 내역을 자연어로 요약
    - 리뷰어의 시간 절약

## 비개발자를 위한 가치

1. **프로젝트 현황 파악**
    - 기술적 배경 없이도 진행 상황 이해
    - 자연어로 질문하고 답변 받기
2. **의사결정 지원**
    - "어떤 기능이 추가되었나요?"
    - "최근에 어떤 변경이 있었나요?"
3. **커뮤니케이션 개선**
    - 개발 팀과 비개발 팀 간 소통 원활화

---

# 📝 요약

**GitHub Analyzer**는 GitHub 저장소의 코드와 커밋 히스토리를 자동으로 수집하고, AI를 활용하여 자연어 질문에 답변하는 시스템입니다.

## 핵심 특징

- 🤖 **AI 기반**: OpenAI GPT-4 / Claude 활용
- 🔍 **벡터 검색**: ChromaDB로 빠른 정보 검색
- 💬 **자연어 질의**: 코드를 몰라도 질문 가능
- 📊 **통계 대시보드**: 시스템 현황 한눈에 파악
- 🎛️ **서버 제어**: 웹에서 서버 시작/종료 가능
- ☁️ **클라우드 연동**: Supabase로 이력 저장

## 기대 효과

- ⏱️ 코드 이해 시간 단축
- 👥 팀 간 소통 개선
- 🚀 온보딩 속도 2배 향상

---

# 🔮 향후 확장 계획

현재는 단순히 GitHub API를 통해 대상 프로젝트의 커밋 히스토리와 파일 정보를 저장해두고 해당 내용 내에서의 답변을 주는 기능만 가능합니다.

다음과 같은 작업 및 확장이 가능합니다:

## 기능 확장

- 🔹 **질문 유형 자동 분류 로직 설계**
    - 기획, 기술, 히스토리, CS, 현황 등으로 세분화
    - 각 유형에 맞는 최적화된 답변 전략
- 🔹 **백엔드 레포지토리 추가 분석**
    - 프론트엔드와 백엔드를 통합하여 분석
    - 풀스택 프로젝트에 대한 종합적 이해 제공
- 🔹 문서 기반 데이터 추가 분석
    - PRD, IA, 미팅 회고록 등 문서 데이터를 통합하여 분석
    - 소스레벨의 한계를 넘어 서비스 전체 이해 제공

## 외부 도구 연동

- 🔹 **Jira, Notion, Confluence 이슈 및 문서 연동**
    - 프로젝트 관리 도구의 데이터 통합
    - 이슈 트래커와 코드 변경 내역 매핑
- 🔹 **회의록 및 회고 문서 기반 질의응답**
    - 팀 커뮤니케이션 기록 분석
    - 결정 사항 및 행동 아이템 추적

## 고급 분석 기능

- 🔹 **파일 의존성 분석 기반 변경 영향도 예측**
    - 코드 변경 시 영향받는 파일 예측
    - 사이드 이펙트 분석

## 실무 활용 확장

- 🔹 **신규 입사자 온보딩 자동 지원 시스템으로 확장**
    - 프로젝트 온보딩 가이드 자동 생성
    - 학습 경로 추천
    - FAQ 기반 질의응답