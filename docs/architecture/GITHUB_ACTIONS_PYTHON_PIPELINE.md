# GitHub Actions Python ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì„¤ê³„

GitHub Actions í™˜ê²½ì—ì„œ ChromaDBë¥¼ ì„ì‹œë¡œ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  JSON íŒŒì¼ë¡œ exportí•˜ëŠ” íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ë¬¸ì„œì…ë‹ˆë‹¤.

## 1. Python ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°

### 1.1 ë©”ì¸ íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ (`scripts/embed_pipeline.py`)

```python
#!/usr/bin/env python3
"""
GitHub Actions í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì„ë² ë”© íŒŒì´í”„ë¼ì¸
- GitHub APIë¡œ ë°ì´í„° ìˆ˜ì§‘ (commit / diff / file)
- ChromaDBì— ì„ì‹œ ì €ì¥
- ì‹¤í–‰ ì¢…ë£Œ í›„ JSON íŒŒì¼ë¡œ export
"""

import os
import json
import sys
from typing import List, Dict, Any
from datetime import datetime

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import chromadb
from chromadb.config import Settings
from openai import OpenAI
import requests
from github import Github


class EmbeddingPipeline:
    """ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        self.github_token = os.getenv("GITHUB_TOKEN")
        self.openai_key = os.getenv("OPENAI_API_KEY")
        self.repo_owner = os.getenv("TARGET_REPO_OWNER")
        self.repo_name = os.getenv("TARGET_REPO_NAME")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„ì‹œ ì‚¬ìš©)
        self.chroma_client = chromadb.Client(Settings(
            chroma_api_impl="rest",
            chroma_server_host=os.getenv("CHROMA_HOST", "localhost"),
            chroma_server_http_port=int(os.getenv("CHROMA_PORT", "8000"))
        ))
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = OpenAI(api_key=self.openai_key)
        
        # GitHub í´ë¼ì´ì–¸íŠ¸
        self.github_client = Github(self.github_token)
        self.repo = self.github_client.get_repo(f"{self.repo_owner}/{self.repo_name}")
        
        # ì»¬ë ‰ì…˜ ì´ë¦„
        self.collection_name = f"{self.repo_name}-vectors"
        self.collection = None
        
    def setup_collection(self, reset: bool = False):
        """ChromaDB ì»¬ë ‰ì…˜ ìƒì„±/ì´ˆê¸°í™”"""
        if reset:
            try:
                self.chroma_client.delete_collection(self.collection_name)
                print(f"ğŸ—‘ï¸  Deleted existing collection: {self.collection_name}")
            except:
                pass
        
        try:
            self.collection = self.chroma_client.get_collection(self.collection_name)
            print(f"ğŸ“‚ Using existing collection: {self.collection_name}")
        except:
            self.collection = self.chroma_client.create_collection(
                name=self.collection_name,
                metadata={"owner": self.repo_owner, "repo": self.repo_name}
            )
            print(f"âœ¨ Created new collection: {self.collection_name}")
    
    def fetch_commits(self) -> List[Dict[str, Any]]:
        """GitHub APIë¡œ ì»¤ë°‹ ëª©ë¡ ìˆ˜ì§‘"""
        print("ğŸ“Œ Fetching commits from GitHub...")
        commits = []
        page = 1
        per_page = 100
        
        while True:
            url = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}/commits"
            params = {"per_page": per_page, "page": page}
            headers = {
                "Authorization": f"Bearer {self.github_token}",
                "Accept": "application/vnd.github+json"
            }
            
            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if not data:
                break
            
            for commit in data:
                commits.append({
                    "sha": commit["sha"],
                    "message": commit["commit"]["message"],
                    "author": commit["commit"]["author"]["name"],
                    "date": commit["commit"]["author"]["date"],
                    "url": commit["html_url"]
                })
            
            if len(data) < per_page:
                break
            page += 1
        
        print(f"   â†’ Fetched {len(commits)} commits")
        return commits
    
    def fetch_commit_files(self, sha: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì»¤ë°‹ì˜ ë³€ê²½ íŒŒì¼ ë° diff ìˆ˜ì§‘"""
        commit = self.repo.get_commit(sha)
        files = []
        
        for file in commit.files:
            files.append({
                "filename": file.filename,
                "status": file.status,  # added, modified, removed
                "additions": file.additions,
                "deletions": file.deletions,
                "patch": file.patch,  # diff ë‚´ìš©
                "sha": file.sha
            })
        
        return files
    
    def fetch_repository_files(self) -> List[Dict[str, Any]]:
        """ë ˆí¬ì§€í† ë¦¬ ì „ì²´ ì†ŒìŠ¤ íŒŒì¼ ìˆ˜ì§‘"""
        print("ğŸ“Œ Fetching repository files...")
        files = []
        
        def traverse_tree(tree, path=""):
            """ì¬ê·€ì ìœ¼ë¡œ íŠ¸ë¦¬ ìˆœíšŒ"""
            for item in tree:
                if item.type == "blob":  # íŒŒì¼
                    # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì œì™¸ (500KB ì´ìƒ)
                    if item.size > 500 * 1024:
                        continue
                    
                    # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì œì™¸
                    try:
                        content = item.decoded_content.decode("utf-8")
                    except:
                        continue
                    
                    file_path = f"{path}/{item.name}" if path else item.name
                    files.append({
                        "path": file_path,
                        "content": content,
                        "size": item.size,
                        "sha": item.sha
                    })
                elif item.type == "tree":  # ë””ë ‰í† ë¦¬
                    new_path = f"{path}/{item.name}" if path else item.name
                    subtree = self.repo.get_git_tree(item.sha, recursive=True)
                    traverse_tree(subtree.tree, new_path)
        
        # ê¸°ë³¸ ë¸Œëœì¹˜ì˜ íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
        default_branch = self.repo.default_branch
        branch = self.repo.get_branch(default_branch)
        tree = self.repo.get_git_tree(branch.commit.sha, recursive=True)
        traverse_tree(tree.tree)
        
        print(f"   â†’ Fetched {len(files)} files")
        return files
    
    def generate_embedding(self, text: str) -> List[float]:
        """OpenAI APIë¡œ ì„ë² ë”© ìƒì„±"""
        response = self.openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def refine_commit_data(self, commit: Dict[str, Any], files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì»¤ë°‹ ë°ì´í„°ë¥¼ NLP ì…ë ¥ í˜•íƒœë¡œ ì •ì œ"""
        file_list = ", ".join([f["filename"] for f in files])
        content = f"{commit['message']} | Files: {file_list}"
        
        return {
            "type": "commit",
            "id": f"commit-{commit['sha']}",
            "content": content,
            "metadata": {
                "type": "commit",
                "sha": commit["sha"],
                "author": commit["author"],
                "date": commit["date"],
                "fileCount": len(files),
                "url": commit["url"]
            }
        }
    
    def refine_diff_data(self, commit_sha: str, file: Dict[str, Any]) -> Dict[str, Any]:
        """Diff ë°ì´í„°ë¥¼ NLP ì…ë ¥ í˜•íƒœë¡œ ì •ì œ"""
        content = f"{file['filename']}: {file['patch'] or 'No changes'}"
        
        return {
            "type": "diff",
            "id": f"diff-{commit_sha}-{file['filename']}",
            "content": content,
            "metadata": {
                "type": "diff",
                "commitSha": commit_sha,
                "filename": file["filename"],
                "status": file["status"],
                "additions": file["additions"],
                "deletions": file["deletions"]
            }
        }
    
    def refine_file_data(self, file: Dict[str, Any], chunk_index: int = 0, total_chunks: int = 1) -> Dict[str, Any]:
        """íŒŒì¼ ë°ì´í„°ë¥¼ NLP ì…ë ¥ í˜•íƒœë¡œ ì •ì œ (ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì²­í¬ ë¶„í• )"""
        # 5KB ì´ìƒ íŒŒì¼ì€ ì²­í¬ ë¶„í• 
        chunk_size = 5000
        if len(file["content"]) > chunk_size:
            chunks = [file["content"][i:i+chunk_size] 
                     for i in range(0, len(file["content"]), chunk_size)]
            content = chunks[chunk_index] if chunk_index < len(chunks) else chunks[0]
            total_chunks = len(chunks)
        else:
            content = file["content"]
        
        content = f"{file['path']}: {content}"
        
        return {
            "type": "file",
            "id": f"file-{file['sha']}-{chunk_index}",
            "content": content,
            "metadata": {
                "type": "file",
                "path": file["path"],
                "size": file["size"],
                "sha": file["sha"],
                "chunkIndex": chunk_index if total_chunks > 1 else None,
                "totalChunks": total_chunks if total_chunks > 1 else None
            }
        }
    
    def process_commits(self, commits: List[Dict[str, Any]]):
        """ì»¤ë°‹ ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„±"""
        print("\nğŸ“Œ Processing commits...")
        
        for i, commit in enumerate(commits):
            if (i + 1) % 10 == 0:
                print(f"   â†’ Processing commit {i + 1}/{len(commits)}")
            
            # ì»¤ë°‹ì˜ ë³€ê²½ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
            files = self.fetch_commit_files(commit["sha"])
            
            # 1. ì»¤ë°‹ ë ˆë²¨ ì„ë² ë”©
            commit_item = self.refine_commit_data(commit, files)
            embedding = self.generate_embedding(commit_item["content"])
            
            self.collection.add(
                ids=[commit_item["id"]],
                embeddings=[embedding],
                documents=[commit_item["content"]],
                metadatas=[commit_item["metadata"]]
            )
            
            # 2. Diff ë ˆë²¨ ì„ë² ë”© (ê° íŒŒì¼ë³„)
            for file in files:
                if file["patch"]:  # diffê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    diff_item = self.refine_diff_data(commit["sha"], file)
                    embedding = self.generate_embedding(diff_item["content"])
                    
                    self.collection.add(
                        ids=[diff_item["id"]],
                        embeddings=[embedding],
                        documents=[diff_item["content"]],
                        metadatas=[diff_item["metadata"]]
                    )
        
        print(f"   â†’ Processed {len(commits)} commits")
    
    def process_repository_files(self, files: List[Dict[str, Any]]):
        """ë ˆí¬ì§€í† ë¦¬ íŒŒì¼ ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„±"""
        print("\nğŸ“Œ Processing repository files...")
        
        for i, file in enumerate(files):
            if (i + 1) % 50 == 0:
                print(f"   â†’ Processing file {i + 1}/{len(files)}")
            
            # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í¬ ë¶„í• 
            chunk_size = 5000
            if len(file["content"]) > chunk_size:
                chunks = [file["content"][j:j+chunk_size] 
                         for j in range(0, len(file["content"]), chunk_size)]
                for chunk_idx, chunk_content in enumerate(chunks):
                    file["content"] = chunk_content
                    file_item = self.refine_file_data(file, chunk_idx, len(chunks))
                    embedding = self.generate_embedding(file_item["content"])
                    
                    self.collection.add(
                        ids=[file_item["id"]],
                        embeddings=[embedding],
                        documents=[file_item["content"]],
                        metadatas=[file_item["metadata"]]
                    )
            else:
                file_item = self.refine_file_data(file)
                embedding = self.generate_embedding(file_item["content"])
                
                self.collection.add(
                    ids=[file_item["id"]],
                    embeddings=[embedding],
                    documents=[file_item["content"]],
                    metadatas=[file_item["metadata"]]
                )
        
        print(f"   â†’ Processed {len(files)} files")
    
    def export_to_json(self, output_path: str = "output/embeddings.json") -> str:
        """ChromaDBì—ì„œ ëª¨ë“  ì„ë² ë”©ì„ JSON íŒŒì¼ë¡œ export"""
        print("\nğŸ“¦ Exporting embeddings to JSON...")
        
        # ChromaDBì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        result = self.collection.get(include=["embeddings", "metadatas", "documents"])
        
        if not result["ids"] or len(result["ids"]) == 0:
            raise ValueError("No embeddings found in collection")
        
        print(f"   â†’ Found {len(result['ids'])} embeddings")
        
        # JSON êµ¬ì¡° ìƒì„±
        vector_file = {
            "version": "1.0",
            "dimension": len(result["embeddings"][0]) if result["embeddings"] else 1536,
            "count": len(result["ids"]),
            "createdAt": datetime.now().isoformat(),
            "metadata": {
                "owner": self.repo_owner,
                "repo": self.repo_name
            },
            "vectors": [
                {
                    "id": result["ids"][i],
                    "embedding": result["embeddings"][i],
                    "content": result["documents"][i],
                    "metadata": result["metadatas"][i]
                }
                for i in range(len(result["ids"]))
            ]
        }
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # JSON íŒŒì¼ ì €ì¥
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(vector_file, f, ensure_ascii=False, indent=2)
        
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        print(f"âœ… Exported to: {output_path} ({file_size:.2f} MB)")
        
        return output_path
    
    def run(self, reset: bool = False):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ Starting embedding pipeline\n")
        
        # 1. ChromaDB ì»¬ë ‰ì…˜ ì„¤ì •
        self.setup_collection(reset=reset)
        
        # 2. GitHub ë°ì´í„° ìˆ˜ì§‘
        commits = self.fetch_commits()
        repo_files = self.fetch_repository_files()
        
        # 3. ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„±
        self.process_commits(commits)
        self.process_repository_files(repo_files)
        
        # 4. JSON íŒŒì¼ë¡œ export
        output_path = self.export_to_json()
        
        print("\nâœ… Pipeline completed successfully!")
        return output_path


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="GitHub Actions Embedding Pipeline")
    parser.add_argument("--reset", action="store_true", help="Reset ChromaDB collection")
    parser.add_argument("--output", default="output/embeddings.json", help="Output JSON file path")
    
    args = parser.parse_args()
    
    try:
        pipeline = EmbeddingPipeline()
        output_path = pipeline.run(reset=args.reset)
        print(f"\nğŸ“ Output file: {output_path}")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Pipeline failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
```

### 1.2 requirements.txt

```txt
chromadb>=0.4.0
openai>=1.0.0
PyGithub>=2.0.0
requests>=2.31.0
python-dotenv>=1.0.0
```

## 2. ChromaDB â†’ JSON Export ë¡œì§ ì˜ˆì‹œ

### 2.1 Export í•¨ìˆ˜ (ë…ë¦½ ìŠ¤í¬ë¦½íŠ¸)

```python
#!/usr/bin/env python3
"""
ChromaDBì—ì„œ ì„ë² ë”©ì„ JSON íŒŒì¼ë¡œ exportí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
import gzip
from datetime import datetime
import chromadb
from chromadb.config import Settings


def export_chromadb_to_json(
    collection_name: str,
    output_path: str = "output/embeddings.json",
    compress: bool = True
) -> str:
    """
    ChromaDB ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ì„ë² ë”©ì„ JSON íŒŒì¼ë¡œ export
    
    Args:
        collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        compress: gzip ì••ì¶• ì—¬ë¶€
    
    Returns:
        ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
    """
    print(f"ğŸ“¥ Fetching embeddings from ChromaDB (collection: {collection_name})...")
    
    # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = chromadb.Client(Settings(
        chroma_api_impl="rest",
        chroma_server_host=os.getenv("CHROMA_HOST", "localhost"),
        chroma_server_http_port=int(os.getenv("CHROMA_PORT", "8000"))
    ))
    
    # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
    collection = client.get_collection(name=collection_name)
    
    # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    result = collection.get(include=["embeddings", "metadatas", "documents"])
    
    if not result["ids"] or len(result["ids"]) == 0:
        raise ValueError(f"No embeddings found in collection: {collection_name}")
    
    print(f"   â†’ Found {len(result['ids'])} embeddings")
    
    # JSON êµ¬ì¡° ìƒì„±
    vector_file = {
        "version": "1.0",
        "dimension": len(result["embeddings"][0]) if result["embeddings"] else 1536,
        "count": len(result["ids"]),
        "createdAt": datetime.now().isoformat(),
        "metadata": {
            "collection": collection_name,
            "source": "chromadb"
        },
        "vectors": [
            {
                "id": result["ids"][i],
                "embedding": result["embeddings"][i],
                "content": result["documents"][i] if result["documents"] else "",
                "metadata": result["metadatas"][i] if result["metadatas"] else {}
            }
            for i in range(len(result["ids"]))
        ]
    }
    
    # JSON ì§ë ¬í™”
    json_string = json.dumps(vector_file, ensure_ascii=False, indent=2)
    json_size = len(json_string.encode("utf-8"))
    print(f"   â†’ JSON size: {json_size / 1024 / 1024:.2f} MB")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # ì••ì¶• ì—¬ë¶€ì— ë”°ë¼ ì €ì¥
    if compress:
        print("   â†’ Compressing with gzip...")
        final_path = f"{output_path}.gz"
        with gzip.open(final_path, "wt", encoding="utf-8") as f:
            f.write(json_string)
        
        compressed_size = os.path.getsize(final_path)
        ratio = ((1 - compressed_size / json_size) * 100)
        print(f"   â†’ Compressed: {compressed_size / 1024 / 1024:.2f} MB (-{ratio:.1f}%)")
    else:
        final_path = output_path
        with open(final_path, "w", encoding="utf-8") as f:
            f.write(json_string)
    
    print(f"âœ… Exported to: {final_path}")
    return final_path


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Export ChromaDB embeddings to JSON")
    parser.add_argument("--collection", required=True, help="ChromaDB collection name")
    parser.add_argument("--output", default="output/embeddings.json", help="Output file path")
    parser.add_argument("--no-compress", action="store_true", help="Disable gzip compression")
    
    args = parser.parse_args()
    
    try:
        output_path = export_chromadb_to_json(
            collection_name=args.collection,
            output_path=args.output,
            compress=not args.no_compress
        )
        print(f"\nğŸ“ Output file: {output_path}")
    except Exception as e:
        print(f"\nâŒ Export failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
```

### 2.2 Export JSON ìŠ¤í‚¤ë§ˆ

```json
{
  "version": "1.0",
  "dimension": 1536,
  "count": 1234,
  "createdAt": "2024-01-15T10:30:00Z",
  "metadata": {
    "owner": "username",
    "repo": "repo-name",
    "collection": "repo-name-vectors",
    "source": "chromadb"
  },
  "vectors": [
    {
      "id": "commit-abc123",
      "embedding": [0.123, -0.456, ...],
      "content": "feat: Add new feature | Files: src/index.ts, src/utils.ts",
      "metadata": {
        "type": "commit",
        "sha": "abc123",
        "author": "John Doe",
        "date": "2024-01-15T10:00:00Z",
        "fileCount": 2
      }
    },
    {
      "id": "diff-abc123-src/index.ts",
      "embedding": [0.789, -0.012, ...],
      "content": "src/index.ts: +export function newFeature() {...}",
      "metadata": {
        "type": "diff",
        "commitSha": "abc123",
        "filename": "src/index.ts",
        "status": "modified",
        "additions": 10,
        "deletions": 5
      }
    },
    {
      "id": "file-xyz789-0",
      "embedding": [0.345, 0.678, ...],
      "content": "src/components/Button.tsx: export const Button = () => {...}",
      "metadata": {
        "type": "file",
        "path": "src/components/Button.tsx",
        "size": 1234,
        "sha": "xyz789",
        "chunkIndex": null,
        "totalChunks": null
      }
    }
  ]
}
```

## 3. GitHub Actions Workflow ì˜ˆì‹œ

### 3.1 ê¸°ë³¸ Workflow (`.github/workflows/embed-pipeline.yml`)

```yaml
name: Embedding Pipeline (Python)

on:
  # ìŠ¤ì¼€ì¤„ ì‹¤í–‰ (ë§¤ì£¼ ì¼ìš”ì¼ 03:00 KST)
  schedule:
    - cron: "0 18 * * 0"  # UTC 18:00 = KST 03:00 (ë‹¤ìŒë‚ )
  
  # ìˆ˜ë™ ì‹¤í–‰
  workflow_dispatch:
    inputs:
      reset:
        description: "Reset ChromaDB collection"
        required: false
        type: boolean
        default: false

# ë™ì‹œ ì‹¤í–‰ ë°©ì§€
concurrency:
  group: embedding-pipeline-${{ github.ref }}
  cancel-in-progress: true

jobs:
  embed:
    name: Generate Embeddings
    runs-on: ubuntu-latest
    timeout-minutes: 60  # 1ì‹œê°„ ì œí•œ

    # ChromaDB ì„œë¹„ìŠ¤ (ì„ì‹œ ì‚¬ìš©)
    services:
      chromadb:
        image: chromadb/chroma:latest
        ports:
          - 8000:8000
        options: >-
          --health-cmd "curl -f http://localhost:8000/api/v1/heartbeat || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Wait for ChromaDB
        run: |
          echo "Waiting for ChromaDB service..."
          timeout 30 bash -c 'until curl -f http://localhost:8000/api/v1/heartbeat; do sleep 2; done'
          echo "âœ… ChromaDB is ready!"

      - name: Run embedding pipeline
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          TARGET_REPO_OWNER: ${{ secrets.TARGET_REPO_OWNER }}
          TARGET_REPO_NAME: ${{ secrets.TARGET_REPO_NAME }}
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          python scripts/embed_pipeline.py --reset=${{ inputs.reset }}

      - name: Export embeddings to JSON
        if: always()
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          python scripts/export_embeddings.py \
            --collection ${{ secrets.TARGET_REPO_NAME }}-vectors \
            --output output/embeddings.json.gz

      - name: Commit embeddings file
        if: always()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸
          if [ -n "$(git status --porcelain output/embeddings.json.gz)" ]; then
            git add output/embeddings.json.gz
            git commit -m "chore: Update embeddings [skip ci]"
            git push
            echo "âœ… Committed embeddings.json.gz"
          else
            echo "â„¹ï¸  No changes to commit"
          fi

      - name: Upload embeddings artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: embeddings-${{ github.run_number }}
          path: output/embeddings.json.gz
          retention-days: 30

      - name: Summary
        if: always()
        run: |
          echo "## ğŸš€ Embedding Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Number**: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Reset Mode**: ${{ inputs.reset }}" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "output/embeddings.json.gz" ]; then
            SIZE=$(du -h output/embeddings.json.gz | cut -f1)
            echo "- **File Size**: $SIZE" >> $GITHUB_STEP_SUMMARY
          fi
```

### 3.2 ê°œì„ ëœ Workflow (ì—ëŸ¬ ì²˜ë¦¬ ë° ìµœì í™”)

```yaml
name: Embedding Pipeline (Python) - Optimized

on:
  schedule:
    - cron: "0 18 * * 0"
  workflow_dispatch:
    inputs:
      reset:
        description: "Reset ChromaDB collection"
        required: false
        type: boolean
        default: false

concurrency:
  group: embedding-pipeline-${{ github.ref }}
  cancel-in-progress: true

jobs:
  embed:
    name: Generate Embeddings
    runs-on: ubuntu-latest
    timeout-minutes: 60

    services:
      chromadb:
        image: chromadb/chroma:latest
        ports:
          - 8000:8000
        options: >-
          --health-cmd "curl -f http://localhost:8000/api/v1/heartbeat || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # ì „ì²´ íˆìŠ¤í† ë¦¬ (ì»¤ë°‹ ì •ë³´ í•„ìš”)

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Wait for ChromaDB
        run: |
          echo "â³ Waiting for ChromaDB service..."
          for i in {1..15}; do
            if curl -f http://localhost:8000/api/v1/heartbeat > /dev/null 2>&1; then
              echo "âœ… ChromaDB is ready!"
              exit 0
            fi
            echo "   Attempt $i/15..."
            sleep 2
          done
          echo "âŒ ChromaDB failed to start"
          exit 1

      - name: Verify ChromaDB health
        run: |
          curl -f http://localhost:8000/api/v1/heartbeat
          echo "âœ… ChromaDB health check passed"

      - name: Run embedding pipeline
        id: pipeline
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          TARGET_REPO_OWNER: ${{ secrets.TARGET_REPO_OWNER }}
          TARGET_REPO_NAME: ${{ secrets.TARGET_REPO_NAME }}
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          set -e
          echo "ğŸš€ Starting embedding pipeline..."
          python scripts/embed_pipeline.py --reset=${{ inputs.reset }} 2>&1 | tee pipeline.log
          
          # ê²°ê³¼ íŒŒì‹±
          if [ -f "pipeline.log" ]; then
            EMBEDDING_COUNT=$(grep -oP 'Found \K\d+' pipeline.log | tail -1 || echo "0")
            echo "embedding_count=$EMBEDDING_COUNT" >> $GITHUB_OUTPUT
          fi

      - name: Export embeddings to JSON
        if: steps.pipeline.outcome == 'success'
        id: export
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          set -e
          echo "ğŸ“¦ Exporting embeddings..."
          python scripts/export_embeddings.py \
            --collection ${{ secrets.TARGET_REPO_NAME }}-vectors \
            --output output/embeddings.json.gz
          
          # íŒŒì¼ í¬ê¸° í™•ì¸
          if [ -f "output/embeddings.json.gz" ]; then
            FILE_SIZE=$(du -h output/embeddings.json.gz | cut -f1)
            echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
            echo "âœ… Exported: $FILE_SIZE"
          fi

      - name: Validate JSON file
        if: steps.export.outcome == 'success'
        run: |
          echo "ğŸ” Validating embeddings.json.gz..."
          gunzip -c output/embeddings.json.gz | python -m json.tool > /dev/null
          echo "âœ… JSON validation passed"
          
          # ê¸°ë³¸ í†µê³„ ì¶œë ¥
          COUNT=$(gunzip -c output/embeddings.json.gz | python -c "import sys, json; data=json.load(sys.stdin); print(data['count'])")
          DIMENSION=$(gunzip -c output/embeddings.json.gz | python -c "import sys, json; data=json.load(sys.stdin); print(data['dimension'])")
          echo "   â†’ Count: $COUNT embeddings"
          echo "   â†’ Dimension: $DIMENSION"

      - name: Commit embeddings file
        if: steps.export.outcome == 'success'
        id: commit
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # ë³€ê²½ì‚¬í•­ í™•ì¸
          git add output/embeddings.json.gz
          
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "chore: Update embeddings [skip ci]

            - Generated: ${{ github.run_number }}
            - Embeddings: ${{ steps.pipeline.outputs.embedding_count }}
            - File size: ${{ steps.export.outputs.file_size }}
            - Triggered by: ${{ github.event_name }}"
            
            git push
            echo "âœ… Committed embeddings.json.gz"
            echo "committed=true" >> $GITHUB_OUTPUT
          else
            echo "â„¹ï¸  No changes to commit"
            echo "committed=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload embeddings artifact
        if: steps.export.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: embeddings-${{ github.run_number }}
          path: output/embeddings.json.gz
          retention-days: 30
          compression-level: 0  # ì´ë¯¸ ì••ì¶•ë¨

      - name: Upload pipeline logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: pipeline.log
          retention-days: 7

      - name: Summary
        if: always()
        run: |
          echo "## ğŸš€ Embedding Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| í•­ëª© | ê°’ |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-----|" >> $GITHUB_STEP_SUMMARY
          echo "| Run Number | ${{ github.run_number }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Triggered by | ${{ github.event_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Reset Mode | ${{ inputs.reset }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Embeddings Count | ${{ steps.pipeline.outputs.embedding_count }} |" >> $GITHUB_STEP_SUMMARY
          echo "| File Size | ${{ steps.export.outputs.file_size }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Committed | ${{ steps.commit.outputs.committed }} |" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.pipeline.outcome }}" == "success" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âœ… **Pipeline completed successfully!**" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âŒ **Pipeline failed. Check logs for details.**" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Cleanup on failure
        if: failure()
        run: |
          echo "ğŸ§¹ Cleaning up on failure..."
          # ChromaDBëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë¨ (ì„œë¹„ìŠ¤ ì¢…ë£Œ ì‹œ)
          echo "âœ… Cleanup completed"
```

## 4. ì‹¤í–‰ íë¦„ ìš”ì•½

```
1. GitHub Actions ì‹œì‘
   â†“
2. ChromaDB ì„œë¹„ìŠ¤ ì‹œì‘ (Docker ì»¨í…Œì´ë„ˆ)
   â†“
3. Python í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜
   â†“
4. ChromaDB í—¬ìŠ¤ì²´í¬ ëŒ€ê¸°
   â†“
5. ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
   â”œâ”€ GitHub APIë¡œ ì»¤ë°‹ ìˆ˜ì§‘
   â”œâ”€ ê° ì»¤ë°‹ì˜ diff ìˆ˜ì§‘
   â”œâ”€ ë ˆí¬ì§€í† ë¦¬ íŒŒì¼ ìˆ˜ì§‘
   â”œâ”€ ë°ì´í„° ì •ì œ (NLP í˜•ì‹)
   â”œâ”€ OpenAI APIë¡œ ì„ë² ë”© ìƒì„±
   â””â”€ ChromaDBì— ì €ì¥
   â†“
6. ChromaDB â†’ JSON Export
   â”œâ”€ ëª¨ë“  ì„ë² ë”© ì¡°íšŒ
   â”œâ”€ JSON êµ¬ì¡° ìƒì„±
   â””â”€ gzip ì••ì¶• í›„ ì €ì¥
   â†“
7. JSON íŒŒì¼ì„ ë ˆí¬ì§€í† ë¦¬ì— ì»¤ë°‹
   â†“
8. Artifactë¡œ ë°±ì—… ì €ì¥
   â†“
9. ChromaDB ì„œë¹„ìŠ¤ ì¢…ë£Œ (ìë™ ì •ë¦¬)
```

## 5. ì£¼ìš” íŠ¹ì§•

### 5.1 ChromaDB ì„ì‹œ ì‚¬ìš©
- GitHub Actions ì‹¤í–‰ ì¤‘ì—ë§Œ ChromaDB Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
- ì‹¤í–‰ ì¢…ë£Œ í›„ ìë™ìœ¼ë¡œ ì •ë¦¬ë¨ (ë¹„ìš© ì—†ìŒ)
- ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ë¡œ ì•ˆì •ì„± ë³´ì¥

### 5.2 ë°ì´í„° ìˆ˜ì§‘ ì „ëµ
- **Commit ë ˆë²¨**: ì»¤ë°‹ ë©”ì‹œì§€ + ë³€ê²½ íŒŒì¼ ëª©ë¡
- **Diff ë ˆë²¨**: ê° íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ (patch)
- **File ë ˆë²¨**: ì „ì²´ ì†ŒìŠ¤ ì½”ë“œ (ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì²­í¬ ë¶„í• )

### 5.3 Export ìµœì í™”
- gzip ì••ì¶•ìœ¼ë¡œ íŒŒì¼ í¬ê¸° ê°ì†Œ (ì•½ 70-80% ì••ì¶•ë¥ )
- JSON ìŠ¤í‚¤ë§ˆì— ë©”íƒ€ë°ì´í„° í¬í•¨ (ë²„ì „, ì°¨ì›, ìƒì„±ì¼ì‹œ)
- ë²¡í„° ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ ì €ì¥

### 5.4 ì—ëŸ¬ ì²˜ë¦¬
- ê° ë‹¨ê³„ë³„ ì„±ê³µ/ì‹¤íŒ¨ ì²´í¬
- ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì €ì¥ ë° Artifact ë°±ì—…
- ChromaDB í—¬ìŠ¤ì²´í¬ ì¬ì‹œë„ ë¡œì§

## 6. ì‚¬ìš© ì˜ˆì‹œ

### 6.1 ë¡œì»¬ í…ŒìŠ¤íŠ¸ (ChromaDB ìˆ˜ë™ ì‹¤í–‰)

```bash
# ChromaDB ì‹œì‘
docker run -d -p 8000:8000 chromadb/chroma:latest

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export GITHUB_TOKEN="ghp_xxx"
export OPENAI_API_KEY="sk-xxx"
export TARGET_REPO_OWNER="username"
export TARGET_REPO_NAME="repo-name"
export CHROMA_HOST="localhost"
export CHROMA_PORT="8000"

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python scripts/embed_pipeline.py

# Export
python scripts/export_embeddings.py \
  --collection repo-name-vectors \
  --output output/embeddings.json.gz
```

### 6.2 GitHub Actionsì—ì„œ ì‹¤í–‰

```bash
# ìˆ˜ë™ ì‹¤í–‰ (GitHub Actions UI)
# workflow_dispatch ì‚¬ìš©

# ë˜ëŠ” ìŠ¤ì¼€ì¤„ ì‹¤í–‰ ëŒ€ê¸°
# ë§¤ì£¼ ì¼ìš”ì¼ 03:00 KST ìë™ ì‹¤í–‰
```

## 7. ì£¼ì˜ì‚¬í•­

1. **API Rate Limit**: GitHub APIì™€ OpenAI APIì˜ rate limit ê³ ë ¤
2. **ì‹¤í–‰ ì‹œê°„**: ëŒ€ìš©ëŸ‰ ë ˆí¬ì§€í† ë¦¬ëŠ” 60ë¶„ ì œí•œ ì´ˆê³¼ ê°€ëŠ¥
3. **ë¹„ìš©**: OpenAI API ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ë¹„ìš© ë°œìƒ
4. **ë³´ì•ˆ**: Secretsì— API í‚¤ ì €ì¥ í•„ìˆ˜
5. **ChromaDB ë°ì´í„°**: ì‹¤í–‰ ì¢…ë£Œ í›„ ìë™ ì‚­ì œë˜ë¯€ë¡œ export í•„ìˆ˜

## 8. ê°œì„  ê°€ëŠ¥í•œ ë¶€ë¶„

1. **ì¦ë¶„ ì—…ë°ì´íŠ¸**: ì´ì „ ì»¤ë°‹ ìƒíƒœ ì €ì¥í•˜ì—¬ ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì²˜ë¦¬
2. **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ ì»¤ë°‹/íŒŒì¼ì„ ë™ì‹œì— ì²˜ë¦¬
3. **ì²­í¬ ìµœì í™”**: íŒŒì¼ ì²­í¬ í¬ê¸° ë™ì  ì¡°ì •
4. **ìºì‹±**: ë™ì¼í•œ íŒŒì¼ ì¬ì²˜ë¦¬ ë°©ì§€
5. **ëª¨ë‹ˆí„°ë§**: ì‹¤í–‰ ì‹œê°„ ë° API ì‚¬ìš©ëŸ‰ ì¶”ì 

