/**
 * ì„ë² ë”©ì„ ì •ì  íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (Serverless ë°°í¬ìš©)
 *
 * ChromaDB/Supabaseì— ì €ì¥ëœ ì„ë² ë”©ì„ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´
 * CDN/Blob Storageì— ì—…ë¡œë“œí•˜ì—¬ ì„œë²„ ë¹„ìš© 0ì› ë‹¬ì„±
 */

import fs from "fs";
import path from "path";
import { promisify } from "util";
import { gzip } from "zlib";
import type { EmbeddingItem } from "../../shared/models/EmbeddingItem.js";

const gzipAsync = promisify(gzip);

export interface ExportOptions {
    /** ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: output/embeddings.json) */
    outputPath?: string;
    /** gzip ì••ì¶• ì—¬ë¶€ (ê¸°ë³¸: true) */
    compress?: boolean;
    /** Vercel Blob ì—…ë¡œë“œ ì—¬ë¶€ */
    uploadToVercelBlob?: boolean;
    /** S3 ì—…ë¡œë“œ ì„¤ì • */
    uploadToS3?: {
        bucket: string;
        region?: string;
        key?: string;
    };
}

interface VectorFile {
    version: string;
    dimension: number;
    count: number;
    createdAt: string;
    metadata: {
        owner: string;
        repo: string;
    };
    vectors: Array<{
        id: string;
        embedding: number[];
        content: string;
        metadata: Record<string, any>;
    }>;
}

/**
 * ì„ë² ë”©ì„ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
 */
export async function exportEmbeddingsToFile(
    items: EmbeddingItem[],
    options: ExportOptions = {}
): Promise<string> {
    const {
        outputPath = "output/embeddings.json",
        compress = true,
        uploadToVercelBlob = false,
        uploadToS3
    } = options;

    console.log(`\nğŸ“¦ Exporting ${items.length} embeddings to file...`);

    // 1. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
        fs.mkdirSync(outputDir, { recursive: true });
    }

    // 2. JSON êµ¬ì¡° ìƒì„±
    const vectorFile: VectorFile = {
        version: "1.0",
        dimension: items[0]?.embedding.length || 1536,
        count: items.length,
        createdAt: new Date().toISOString(),
        metadata: {
            owner: process.env.TARGET_REPO_OWNER || "",
            repo: process.env.TARGET_REPO_NAME || ""
        },
        vectors: items.map(item => ({
            id: item.id,
            embedding: item.embedding,
            content: item.content,
            metadata: item.metadata
        }))
    };

    // 3. JSON ì§ë ¬í™”
    const jsonString = JSON.stringify(vectorFile);
    const jsonSize = Buffer.byteLength(jsonString, 'utf-8');
    console.log(`   â†’ JSON size: ${(jsonSize / 1024 / 1024).toFixed(2)} MB`);

    // 4. ì••ì¶• (ì„ íƒ)
    let finalBuffer: Buffer;
    let finalPath = outputPath;

    if (compress) {
        console.log("   â†’ Compressing with gzip...");
        finalBuffer = await gzipAsync(jsonString);
        finalPath = `${outputPath}.gz`;
        const compressedSize = finalBuffer.length;
        const ratio = ((1 - compressedSize / jsonSize) * 100).toFixed(1);
        console.log(`   â†’ Compressed: ${(compressedSize / 1024 / 1024).toFixed(2)} MB (-${ratio}%)`);
    } else {
        finalBuffer = Buffer.from(jsonString, 'utf-8');
    }

    // 5. ë¡œì»¬ íŒŒì¼ ì €ì¥
    fs.writeFileSync(finalPath, finalBuffer);
    console.log(`âœ… Saved to: ${finalPath}`);

    // 6. í´ë¼ìš°ë“œ ì—…ë¡œë“œ (ì„ íƒ)
    if (uploadToVercelBlob) {
        await uploadToVercel(finalBuffer, finalPath);
    }

    if (uploadToS3) {
        await uploadToAWSS3(finalBuffer, uploadToS3);
    }

    return finalPath;
}

/**
 * Vercel Blob Storageì— ì—…ë¡œë“œ
 */
async function uploadToVercel(buffer: Buffer, filePath: string): Promise<void> {
    const token = process.env.BLOB_READ_WRITE_TOKEN;

    if (!token) {
        console.warn("âš ï¸  BLOB_READ_WRITE_TOKEN not set, skipping Vercel Blob upload");
        return;
    }

    try {
        console.log("   â†’ Uploading to Vercel Blob...");

        const { put } = await import("@vercel/blob");

        const blob = await put(path.basename(filePath), buffer, {
            access: 'public',
            token,
            addRandomSuffix: false
        });

        console.log(`âœ… Uploaded to Vercel Blob: ${blob.url}`);
        console.log(`   â†’ Set VECTOR_FILE_URL=${blob.url} in production`);

    } catch (error: any) {
        console.error("âŒ Vercel Blob upload failed:", error.message);
        throw error;
    }
}

/**
 * AWS S3ì— ì—…ë¡œë“œ
 */
async function uploadToAWSS3(
    buffer: Buffer,
    config: { bucket: string; region?: string; key?: string }
): Promise<void> {
    const { bucket, region = "us-east-1", key = "embeddings.json.gz" } = config;

    try {
        console.log(`   â†’ Uploading to S3: s3://${bucket}/${key}...`);

        const { S3Client, PutObjectCommand } = await import("@aws-sdk/client-s3");

        const client = new S3Client({ region });

        await client.send(new PutObjectCommand({
            Bucket: bucket,
            Key: key,
            Body: buffer,
            ContentType: key.endsWith('.gz') ? 'application/gzip' : 'application/json',
            ContentEncoding: key.endsWith('.gz') ? 'gzip' : undefined,
            CacheControl: 'public, max-age=3600',  // 1ì‹œê°„ CDN ìºì‹±
            Metadata: {
                'generated-at': new Date().toISOString()
            }
        }));

        const url = `https://${bucket}.s3.${region}.amazonaws.com/${key}`;
        console.log(`âœ… Uploaded to S3: ${url}`);
        console.log(`   â†’ Set VECTOR_FILE_URL=${url} in production`);

    } catch (error: any) {
        console.error("âŒ S3 upload failed:", error.message);
        throw error;
    }
}

/**
 * Supabaseì—ì„œ ì„ë² ë”© ì½ì–´ì„œ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
 */
export async function exportFromSupabase(options: ExportOptions = {}): Promise<string> {
    console.log("ğŸ“¥ Fetching embeddings from Supabase...");

    const { SupabaseVectorStore } = await import("./supabaseVectorStore.js");
    const vectorStore = new SupabaseVectorStore();

    const owner = process.env.TARGET_REPO_OWNER || "";
    const repo = process.env.TARGET_REPO_NAME || "";

    // Supabaseì—ì„œ ëª¨ë“  ì„ë² ë”© ì¡°íšŒ
    const allEmbeddings = await vectorStore.getAllEmbeddings({ owner, repo });

    console.log(`   â†’ Found ${allEmbeddings.length} embeddings`);

    // EmbeddingItem í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const items: EmbeddingItem[] = allEmbeddings.map(item => ({
        id: item.id,
        content: item.content,
        embedding: item.embedding,
        metadata: item.metadata
    }));

    return exportEmbeddingsToFile(items, options);
}

/**
 * ChromaDBì—ì„œ ì„ë² ë”© ì½ì–´ì„œ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
 */
export async function exportFromChromaDB(
    collectionName: string,
    options: ExportOptions = {}
): Promise<string> {
    console.log(`ğŸ“¥ Fetching embeddings from ChromaDB (collection: ${collectionName})...`);

    const { ChromaClient } = await import("chromadb");
    const client = new ChromaClient();

    try {
        const collection = await client.getCollection({ name: collectionName });

        const result = await collection.get({
            include: ["embeddings", "metadatas", "documents"]
        });

        if (!result.ids || result.ids.length === 0) {
            throw new Error("No embeddings found in collection");
        }

        console.log(`   â†’ Found ${result.ids.length} embeddings`);

        // EmbeddingItem í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        const items: EmbeddingItem[] = result.ids.map((id, idx) => ({
            id,
            content: result.documents?.[idx] || "",
            embedding: result.embeddings?.[idx] || [],
            metadata: result.metadatas?.[idx] || {}
        }));

        return exportEmbeddingsToFile(items, options);

    } catch (error: any) {
        console.error("âŒ ChromaDB export failed:", error.message);
        throw error;
    }
}
